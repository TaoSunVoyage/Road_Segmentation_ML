{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1bgDY-_4fSH8",
        "colab_type": "code",
        "outputId": "a5a36ce7-edd5-4f4f-f931-08245946a4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UWnI4AylsDG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path = \"training\"\n",
        "test_path = \"test_set_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBuqpjeEr_NQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import tensorflow as tf\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oA3rwAgMr_Nj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U57_hYj3k1qp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# foreground_threshold = 0.25\n",
        "\n",
        "# def patch_to_label(patch):\n",
        "#     df = np.mean(patch)\n",
        "#     if df > foreground_threshold:\n",
        "#         return 1\n",
        "#     else:\n",
        "#         return 0\n",
        "      \n",
        "# def get_label(y, patch_size=16):\n",
        "#     label = []\n",
        "#     y_array = K.eval(y[:,:,:,0])\n",
        "#     for im in y_array:\n",
        "#       for j in range(0, im.shape[1], patch_size):\n",
        "#         for i in range(0, im.shape[0], patch_size):\n",
        "#             patch = im[i:i + patch_size, j:j + patch_size]\n",
        "#             label.append(patch_to_label(patch))\n",
        "#     return np.array(label)\n",
        "  \n",
        "# def patch_f1(y_true, y_pred):\n",
        "#     true_label = get_label(y_true)\n",
        "#     pred_label = get_label(y_pred)\n",
        "#     return f1(true_label, pred_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ykKFQvakr_Np",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # credits: https://www.kaggle.com/guglielmocamporese/macro-f1-score-keras\n",
        "\n",
        "# def f1(y_true, y_pred):\n",
        "#     #y_pred = K.round(y_pred)\n",
        "#     #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
        "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "#     p = tp / (tp + fp + K.epsilon())\n",
        "#     r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
        "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "#     return K.mean(f1)\n",
        "  \n",
        "# def f1_loss(y_true, y_pred):\n",
        "    \n",
        "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "#     p = tp / (tp + fp + K.epsilon())\n",
        "#     r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
        "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "#     return 1 - K.mean(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l7Gu5oZgCgie",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d_block(input_tensor, n_filter, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(n_filter, kernel_size=kernel_size, kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(n_filter, kernel_size=kernel_size, kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yp2xDTpr_Nv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unet(pretrained_weights = None,\n",
        "         input_size = (None,None,3),\n",
        "         n_filter=16,\n",
        "         dropout=True, dropout_rate=0.5,\n",
        "         batchnorm=True\n",
        "        ):\n",
        "  \n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    conv1 = conv2d_block(inputs, n_filter, kernel_size=3, batchnorm=batchnorm)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    \n",
        "    conv2 = conv2d_block(pool1, n_filter*2, kernel_size=3, batchnorm=batchnorm)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    \n",
        "    conv3 = conv2d_block(pool2, n_filter*4, kernel_size=3, batchnorm=batchnorm)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    \n",
        "    conv4 = conv2d_block(pool3, n_filter*8, kernel_size=3, batchnorm=batchnorm)\n",
        "    conv4 = Dropout(dropout_rate)(conv4) if dropout else conv4\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = conv2d_block(pool4, n_filter*16, kernel_size=3, batchnorm=batchnorm)\n",
        "    conv5 = Dropout(dropout_rate)(conv5) if dropout else conv5\n",
        "\n",
        "    up6 = UpSampling2D(size = (2, 2))(conv5)\n",
        "    up6 = conv2d_block(up6, n_filter*8, kernel_size=2, batchnorm=batchnorm)\n",
        "    merge6 = concatenate([conv4, up6], axis = 3)\n",
        "    conv6 = conv2d_block(merge6, n_filter*8, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    up7 = UpSampling2D(size = (2, 2))(conv6)\n",
        "    up7 = conv2d_block(up7, n_filter*4, kernel_size=2, batchnorm=batchnorm)\n",
        "    merge7 = concatenate([conv3, up7], axis = 3)\n",
        "    conv7 = conv2d_block(merge7, n_filter*4, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    up8 = UpSampling2D(size = (2, 2))(conv7)\n",
        "    up8 = conv2d_block(up8, n_filter*2, kernel_size=2, batchnorm=batchnorm)\n",
        "    merge8 = concatenate([conv2, up8], axis = 3)\n",
        "    conv8 = conv2d_block(merge8, n_filter*2, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    up9 = UpSampling2D(size = (2, 2))(conv8)\n",
        "    up9 = conv2d_block(up9, n_filter, kernel_size=2, batchnorm=batchnorm)\n",
        "    merge9 = concatenate([conv1, up9], axis = 3)\n",
        "    conv9 = conv2d_block(merge9, n_filter, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "#     conv10 = Conv2D(2, 1, kernel_initializer=\"he_normal\", padding=\"same\")(conv9)\n",
        "#     if batchnorm:\n",
        "#         conv10 = BatchNormalization()(conv10)\n",
        "#     conv10 = Activation(\"relu\")(conv10)\n",
        "    \n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(), loss = 'binary_crossentropy', metrics = [f1, 'accuracy'])\n",
        "    \n",
        "    if(pretrained_weights):\n",
        "        model.load_weights(filepath=pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kz1V64Vojp1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def adjustImage(img, mask):\n",
        "#     img = img/255\n",
        "#     mask = mask/255\n",
        "#     mask[mask > 0.5] = 1\n",
        "#     mask[mask <= 0.5] = 0\n",
        "#     return img, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gYQxiZ6heOr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_mask(mask):\n",
        "    mask = mask/255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "    return mask\n",
        "  \n",
        "def preprocess_img(img):\n",
        "    return img/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rGSyAjtzr_N3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainvalGenerator(batch_size, train_path, image_folder, mask_folder,\n",
        "                      aug_dict, train_dir = None, val_dir = None,\n",
        "                      target_size = (400,400), seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_dict = aug_dict.copy()\n",
        "    image_dict[\"preprocessing_function\"] = preprocess_img\n",
        "    image_datagen = ImageDataGenerator(**image_dict)\n",
        "    \n",
        "    mask_dict = aug_dict.copy()\n",
        "    mask_dict[\"preprocessing_function\"] = preprocess_mask\n",
        "    mask_datagen = ImageDataGenerator(**mask_dict)\n",
        "    \n",
        "    image_generator_train = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = \"rgb\",\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = train_dir,\n",
        "        save_prefix  = \"image\",\n",
        "        seed = seed,\n",
        "        subset = \"training\")\n",
        "    \n",
        "    image_generator_val = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = \"rgb\",\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = val_dir,\n",
        "        save_prefix  = \"image\",\n",
        "        seed = seed+1,\n",
        "        subset = \"validation\")\n",
        "    \n",
        "    mask_generator_train = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = train_dir,\n",
        "        save_prefix  = \"mask\",\n",
        "        seed = seed,\n",
        "        subset = \"training\")\n",
        "    \n",
        "    mask_generator_val = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = val_dir,\n",
        "        save_prefix  = \"mask\",\n",
        "        seed = seed+1,\n",
        "        subset = \"validation\")\n",
        "    \n",
        "    return zip(image_generator_train, mask_generator_train), zip(image_generator_val, mask_generator_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWFE4TUsr_N7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# argument for data augmentation\n",
        "data_gen_args = dict(rotation_range=90,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=True,\n",
        "                     fill_mode='reflect',\n",
        "                     validation_split=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zi8lvAUky7Gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf train_image\n",
        "!rm -rf val_image\n",
        "!mkdir train_image\n",
        "!mkdir val_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Pr23xxNr_N_",
        "colab_type": "code",
        "outputId": "79f3e1b2-b372-4ed2-cf88-053fde6165d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "trainGen, valGen = trainvalGenerator(batch_size=2, \n",
        "                                     train_path=train_path, \n",
        "                                     image_folder='images', mask_folder='groundtruth',\n",
        "                                     aug_dict=data_gen_args, \n",
        "                                     train_dir = \"train_image\",\n",
        "                                     val_dir = \"val_image\",\n",
        "                                     target_size = (400, 400), seed = 1)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100 images belonging to 1 classes.\n",
            "Found 0 images belonging to 1 classes.\n",
            "Found 100 images belonging to 1 classes.\n",
            "Found 0 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "knx3uNw6r_OB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = unet(n_filter=32, dropout=True)\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ReAr6s7r_OG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "#     EarlyStopping(patience=10, verbose=1),\n",
        "#     ModelCheckpoint('weights_no_val.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='loss', patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, min_lr=1e-5),\n",
        "    ModelCheckpoint('weights_no_val_32_10layers_drop.h5', monitor='loss', save_best_only=True, verbose=1),\n",
        "    TensorBoard(log_dir='tensorboard/', write_graph=True, write_images=True)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pokgC4X9r_OX",
        "colab_type": "code",
        "outputId": "52170fdd-c259-4755-b769-fe673c00056d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6171
        }
      },
      "cell_type": "code",
      "source": [
        "print('*'*30)\n",
        "print('Fitting model...')\n",
        "print('*'*30)\n",
        "history = model.fit_generator(generator=trainGen, steps_per_epoch=50,\n",
        "#                               validation_data=valGen, validation_steps=50,\n",
        "                              epochs=500, callbacks=callbacks)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************************\n",
            "Fitting model...\n",
            "******************************\n",
            "Epoch 1/500\n",
            "50/50 [==============================] - 31s 621ms/step - loss: 0.4969 - f1: 0.3242 - acc: 0.7596\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.49692, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 2/500\n",
            "50/50 [==============================] - 24s 487ms/step - loss: 0.4038 - f1: 0.4060 - acc: 0.8157\n",
            "\n",
            "Epoch 00002: loss improved from 0.49692 to 0.40382, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 3/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.3524 - f1: 0.5211 - acc: 0.8375\n",
            "\n",
            "Epoch 00003: loss improved from 0.40382 to 0.35243, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 4/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.3623 - f1: 0.5671 - acc: 0.8377\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.35243\n",
            "Epoch 5/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.3459 - f1: 0.5113 - acc: 0.8381\n",
            "\n",
            "Epoch 00005: loss improved from 0.35243 to 0.34592, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 6/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.3501 - f1: 0.5260 - acc: 0.8408\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.34592\n",
            "Epoch 7/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.3341 - f1: 0.5651 - acc: 0.8481\n",
            "\n",
            "Epoch 00007: loss improved from 0.34592 to 0.33410, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 8/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.3394 - f1: 0.5272 - acc: 0.8396\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.33410\n",
            "Epoch 9/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.3166 - f1: 0.6255 - acc: 0.8586\n",
            "\n",
            "Epoch 00009: loss improved from 0.33410 to 0.31663, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 10/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.3120 - f1: 0.5809 - acc: 0.8562\n",
            "\n",
            "Epoch 00010: loss improved from 0.31663 to 0.31203, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 11/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.2899 - f1: 0.6509 - acc: 0.8750\n",
            "\n",
            "Epoch 00011: loss improved from 0.31203 to 0.28986, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 12/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.2990 - f1: 0.6187 - acc: 0.8676\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.28986\n",
            "Epoch 13/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.3060 - f1: 0.6201 - acc: 0.8646\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.28986\n",
            "Epoch 14/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.2778 - f1: 0.6656 - acc: 0.8813\n",
            "\n",
            "Epoch 00014: loss improved from 0.28986 to 0.27778, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 15/500\n",
            "50/50 [==============================] - 24s 487ms/step - loss: 0.2658 - f1: 0.6681 - acc: 0.8813\n",
            "\n",
            "Epoch 00015: loss improved from 0.27778 to 0.26576, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 16/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.2532 - f1: 0.7149 - acc: 0.8927\n",
            "\n",
            "Epoch 00016: loss improved from 0.26576 to 0.25317, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 17/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.2587 - f1: 0.6914 - acc: 0.8872\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.25317\n",
            "Epoch 18/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.2564 - f1: 0.6949 - acc: 0.8930\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.25317\n",
            "Epoch 19/500\n",
            "50/50 [==============================] - 25s 491ms/step - loss: 0.2477 - f1: 0.7031 - acc: 0.8922\n",
            "\n",
            "Epoch 00019: loss improved from 0.25317 to 0.24772, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 20/500\n",
            "50/50 [==============================] - 25s 491ms/step - loss: 0.2332 - f1: 0.7417 - acc: 0.9016\n",
            "\n",
            "Epoch 00020: loss improved from 0.24772 to 0.23322, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 21/500\n",
            "50/50 [==============================] - 24s 485ms/step - loss: 0.2492 - f1: 0.6935 - acc: 0.8951\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.23322\n",
            "Epoch 22/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.2128 - f1: 0.7759 - acc: 0.9119\n",
            "\n",
            "Epoch 00022: loss improved from 0.23322 to 0.21284, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 23/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.2247 - f1: 0.7321 - acc: 0.9046\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.21284\n",
            "Epoch 24/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.2210 - f1: 0.7587 - acc: 0.9086\n",
            "\n",
            "Epoch 00024: loss did not improve from 0.21284\n",
            "Epoch 25/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.2307 - f1: 0.7480 - acc: 0.9054\n",
            "\n",
            "Epoch 00025: loss did not improve from 0.21284\n",
            "Epoch 26/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.2251 - f1: 0.7504 - acc: 0.9094\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.21284\n",
            "Epoch 27/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.2051 - f1: 0.7842 - acc: 0.9163\n",
            "\n",
            "Epoch 00027: loss improved from 0.21284 to 0.20512, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 28/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.2085 - f1: 0.7592 - acc: 0.9148\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.20512\n",
            "Epoch 29/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.2049 - f1: 0.7788 - acc: 0.9163\n",
            "\n",
            "Epoch 00029: loss improved from 0.20512 to 0.20493, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 30/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.1938 - f1: 0.7871 - acc: 0.9213\n",
            "\n",
            "Epoch 00030: loss improved from 0.20493 to 0.19379, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 31/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.2039 - f1: 0.7740 - acc: 0.9172\n",
            "\n",
            "Epoch 00031: loss did not improve from 0.19379\n",
            "Epoch 32/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.2004 - f1: 0.7818 - acc: 0.9204\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.19379\n",
            "Epoch 33/500\n",
            "50/50 [==============================] - 25s 490ms/step - loss: 0.1971 - f1: 0.7787 - acc: 0.9172\n",
            "\n",
            "Epoch 00033: loss did not improve from 0.19379\n",
            "Epoch 34/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.1972 - f1: 0.7861 - acc: 0.9184\n",
            "\n",
            "Epoch 00034: loss did not improve from 0.19379\n",
            "Epoch 35/500\n",
            "50/50 [==============================] - 25s 490ms/step - loss: 0.1772 - f1: 0.8031 - acc: 0.9279\n",
            "\n",
            "Epoch 00035: loss improved from 0.19379 to 0.17716, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 36/500\n",
            "50/50 [==============================] - 25s 490ms/step - loss: 0.2067 - f1: 0.7802 - acc: 0.9174\n",
            "\n",
            "Epoch 00036: loss did not improve from 0.17716\n",
            "Epoch 37/500\n",
            "50/50 [==============================] - 25s 493ms/step - loss: 0.1987 - f1: 0.7839 - acc: 0.9196\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.17716\n",
            "Epoch 38/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.1829 - f1: 0.7993 - acc: 0.9252\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.17716\n",
            "Epoch 39/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.1824 - f1: 0.8015 - acc: 0.9255\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.17716\n",
            "Epoch 40/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.1732 - f1: 0.8082 - acc: 0.9288\n",
            "\n",
            "Epoch 00040: loss improved from 0.17716 to 0.17323, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 41/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1955 - f1: 0.7836 - acc: 0.9211\n",
            "\n",
            "Epoch 00041: loss did not improve from 0.17323\n",
            "Epoch 42/500\n",
            "50/50 [==============================] - 24s 480ms/step - loss: 0.1746 - f1: 0.8137 - acc: 0.9275\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.17323\n",
            "Epoch 43/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1841 - f1: 0.7959 - acc: 0.9256\n",
            "\n",
            "Epoch 00043: loss did not improve from 0.17323\n",
            "Epoch 44/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1849 - f1: 0.7919 - acc: 0.9248\n",
            "\n",
            "Epoch 00044: loss did not improve from 0.17323\n",
            "Epoch 45/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1717 - f1: 0.8177 - acc: 0.9304\n",
            "\n",
            "Epoch 00045: loss improved from 0.17323 to 0.17173, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 46/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.1593 - f1: 0.8246 - acc: 0.9357\n",
            "\n",
            "Epoch 00046: loss improved from 0.17173 to 0.15934, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 47/500\n",
            "50/50 [==============================] - 24s 485ms/step - loss: 0.1591 - f1: 0.8311 - acc: 0.9356\n",
            "\n",
            "Epoch 00047: loss improved from 0.15934 to 0.15913, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 48/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.1694 - f1: 0.8100 - acc: 0.9316\n",
            "\n",
            "Epoch 00048: loss did not improve from 0.15913\n",
            "Epoch 49/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.1695 - f1: 0.8243 - acc: 0.9320\n",
            "\n",
            "Epoch 00049: loss did not improve from 0.15913\n",
            "Epoch 50/500\n",
            "50/50 [==============================] - 24s 487ms/step - loss: 0.1646 - f1: 0.8181 - acc: 0.9338\n",
            "\n",
            "Epoch 00050: loss did not improve from 0.15913\n",
            "Epoch 51/500\n",
            "50/50 [==============================] - 25s 493ms/step - loss: 0.1622 - f1: 0.8247 - acc: 0.9357\n",
            "\n",
            "Epoch 00051: loss did not improve from 0.15913\n",
            "Epoch 52/500\n",
            "50/50 [==============================] - 25s 492ms/step - loss: 0.1642 - f1: 0.8249 - acc: 0.9332\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 00052: loss did not improve from 0.15913\n",
            "Epoch 53/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1445 - f1: 0.8303 - acc: 0.9403\n",
            "\n",
            "Epoch 00053: loss improved from 0.15913 to 0.14446, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 54/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1563 - f1: 0.8328 - acc: 0.9362\n",
            "\n",
            "Epoch 00054: loss did not improve from 0.14446\n",
            "Epoch 55/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1448 - f1: 0.8476 - acc: 0.9405\n",
            "\n",
            "Epoch 00055: loss did not improve from 0.14446\n",
            "Epoch 56/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.1404 - f1: 0.8424 - acc: 0.9435\n",
            "\n",
            "Epoch 00056: loss improved from 0.14446 to 0.14045, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 57/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1466 - f1: 0.8474 - acc: 0.9399\n",
            "\n",
            "Epoch 00057: loss did not improve from 0.14045\n",
            "Epoch 58/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1351 - f1: 0.8487 - acc: 0.9447\n",
            "\n",
            "Epoch 00058: loss improved from 0.14045 to 0.13510, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 59/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1400 - f1: 0.8462 - acc: 0.9427\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.13510\n",
            "Epoch 60/500\n",
            "50/50 [==============================] - 24s 485ms/step - loss: 0.1402 - f1: 0.8398 - acc: 0.9443\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.13510\n",
            "Epoch 61/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1352 - f1: 0.8630 - acc: 0.9448\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.13510\n",
            "Epoch 62/500\n",
            "50/50 [==============================] - 24s 487ms/step - loss: 0.1322 - f1: 0.8483 - acc: 0.9473\n",
            "\n",
            "Epoch 00062: loss improved from 0.13510 to 0.13223, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 63/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.1345 - f1: 0.8661 - acc: 0.9454\n",
            "\n",
            "Epoch 00063: loss did not improve from 0.13223\n",
            "Epoch 64/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.1379 - f1: 0.8441 - acc: 0.9440\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.13223\n",
            "Epoch 65/500\n",
            "50/50 [==============================] - 25s 491ms/step - loss: 0.1396 - f1: 0.8483 - acc: 0.9439\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.13223\n",
            "Epoch 66/500\n",
            "50/50 [==============================] - 24s 488ms/step - loss: 0.1347 - f1: 0.8534 - acc: 0.9453\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.13223\n",
            "Epoch 67/500\n",
            "50/50 [==============================] - 24s 480ms/step - loss: 0.1283 - f1: 0.8640 - acc: 0.9483\n",
            "\n",
            "Epoch 00067: loss improved from 0.13223 to 0.12830, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 68/500\n",
            "50/50 [==============================] - 24s 480ms/step - loss: 0.1399 - f1: 0.8517 - acc: 0.9434\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.12830\n",
            "Epoch 69/500\n",
            "50/50 [==============================] - 24s 480ms/step - loss: 0.1290 - f1: 0.8544 - acc: 0.9479\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.12830\n",
            "Epoch 70/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.1349 - f1: 0.8518 - acc: 0.9454\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.12830\n",
            "Epoch 71/500\n",
            "50/50 [==============================] - 24s 479ms/step - loss: 0.1289 - f1: 0.8640 - acc: 0.9482\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.12830\n",
            "Epoch 72/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.1284 - f1: 0.8530 - acc: 0.9481\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.12830\n",
            "Epoch 73/500\n",
            "50/50 [==============================] - 24s 481ms/step - loss: 0.1343 - f1: 0.8573 - acc: 0.9450\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.12830\n",
            "Epoch 74/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.1240 - f1: 0.8685 - acc: 0.9505\n",
            "\n",
            "Epoch 00074: loss improved from 0.12830 to 0.12397, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 75/500\n",
            "50/50 [==============================] - 24s 484ms/step - loss: 0.1350 - f1: 0.8498 - acc: 0.9455\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.12397\n",
            "Epoch 76/500\n",
            "50/50 [==============================] - 24s 482ms/step - loss: 0.1202 - f1: 0.8672 - acc: 0.9512\n",
            "\n",
            "Epoch 00076: loss improved from 0.12397 to 0.12020, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 77/500\n",
            "50/50 [==============================] - 24s 485ms/step - loss: 0.1380 - f1: 0.8506 - acc: 0.9445\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.12020\n",
            "Epoch 78/500\n",
            "50/50 [==============================] - 24s 486ms/step - loss: 0.1178 - f1: 0.8775 - acc: 0.9519\n",
            "\n",
            "Epoch 00078: loss improved from 0.12020 to 0.11782, saving model to weights_no_val_32_10layers_drop.h5\n",
            "Epoch 79/500\n",
            "50/50 [==============================] - 24s 483ms/step - loss: 0.1269 - f1: 0.8534 - acc: 0.9474\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.11782\n",
            "Epoch 80/500\n",
            "50/50 [==============================] - 24s 478ms/step - loss: 0.1297 - f1: 0.8588 - acc: 0.9467\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.11782\n",
            "Epoch 81/500\n",
            "50/50 [==============================] - 24s 480ms/step - loss: 0.1246 - f1: 0.8591 - acc: 0.9514\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.11782\n",
            "Epoch 82/500\n",
            "50/50 [==============================] - 24s 477ms/step - loss: 0.1286 - f1: 0.8648 - acc: 0.9485\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.11782\n",
            "Epoch 83/500\n",
            "50/50 [==============================] - 24s 477ms/step - loss: 0.1336 - f1: 0.8497 - acc: 0.9456\n",
            "\n",
            "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.11782\n",
            "Epoch 84/500\n",
            "50/50 [==============================] - 24s 478ms/step - loss: 0.1213 - f1: 0.8730 - acc: 0.9518\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.11782\n",
            "Epoch 85/500\n",
            "50/50 [==============================] - 24s 478ms/step - loss: 0.1337 - f1: 0.8530 - acc: 0.9452\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.11782\n",
            "Epoch 86/500\n",
            "50/50 [==============================] - 24s 479ms/step - loss: 0.1273 - f1: 0.8635 - acc: 0.9489\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.11782\n",
            "Epoch 87/500\n",
            "50/50 [==============================] - 24s 477ms/step - loss: 0.1276 - f1: 0.8651 - acc: 0.9479\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.11782\n",
            "Epoch 88/500\n",
            "50/50 [==============================] - 24s 478ms/step - loss: 0.1355 - f1: 0.8553 - acc: 0.9460\n",
            "\n",
            "Epoch 00088: loss did not improve from 0.11782\n",
            "Epoch 00088: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BsGVNX1nr_Oa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import skimage.io as io\n",
        "def testGenerator(test_path, num_image = 50):\n",
        "    for i in range(1,num_image+1):\n",
        "        img = io.imread(os.path.join(test_path, \"test_%d\"%i, \"test_%d.png\"%i))\n",
        "        img = img / 255\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        yield img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "noWhzXJ3r_Od",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testGene = testGenerator(test_path)\n",
        "# model_predict = unet(pretrained_weights = \"weights_no_val_32.h5\", input_size = (608,608,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2FMkq4er_Og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = unet(n_filter=32)\n",
        "# model.load_weights(filepath=\"weights_no_val_32.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9hZnm9T18vEM",
        "colab_type": "code",
        "outputId": "d08f6f84-03a8-42a3-c1f5-261baf7cce0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "result = model.predict_generator(testGene, 50, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 12s 242ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EdSPM5qRr_Oj",
        "colab_type": "code",
        "outputId": "f622a60e-da66-412a-e7aa-9073f179a2fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "def saveResult(save_path, npyfile):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path, \"%d_predict.png\"%(i+1)), img)\n",
        "\n",
        "!mkdir test        \n",
        "saveResult(\"test\", result)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint16\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lWlLqIgRr_Ol",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import re\n",
        "\n",
        "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
        "\n",
        "# assign a label to a patch\n",
        "def patch_to_label(patch):\n",
        "    df = np.mean(patch)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def mask_to_submission_strings(image_filename):\n",
        "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
        "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
        "    im = mpimg.imread(image_filename)\n",
        "    patch_size = 16\n",
        "    for j in range(0, im.shape[1], patch_size):\n",
        "        for i in range(0, im.shape[0], patch_size):\n",
        "            patch = im[i:i + patch_size, j:j + patch_size]\n",
        "            label = patch_to_label(patch)\n",
        "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
        "\n",
        "\n",
        "def masks_to_submission(submission_filename, *image_filenames):\n",
        "    \"\"\"Converts images into a submission file\"\"\"\n",
        "    with open(submission_filename, 'w') as f:\n",
        "        f.write('id,prediction\\n')\n",
        "        for fn in image_filenames[0:]:\n",
        "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6u0lzjwr_On",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission_filename = 'submission.csv'\n",
        "image_filenames = []\n",
        "predict_path = 'test/'\n",
        "for i in range(1, 51):\n",
        "    image_filename = predict_path + '%d' % i + '_predict.png'\n",
        "#     print(image_filename)\n",
        "    image_filenames.append(image_filename)\n",
        "masks_to_submission(submission_filename, *image_filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXd0XEiwTpJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}