{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "1bgDY-_4fSH8",
    "outputId": "a8b31330-3434-444f-894a-9e3c2603e541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWnI4AylsDG7"
   },
   "outputs": [],
   "source": [
    "train_path = \"drive/My Drive/training\"\n",
    "test_path = \"drive/My Drive/test_set_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OBuqpjeEr_NQ",
    "outputId": "fd8b4fc9-a3dc-4695-88d9-63527d313326"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "-EzAHF-3OhR0",
    "outputId": "559d9e67-0563-4b4b-9efc-cd1c05c57e86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:132: UserWarning: drive/My Drive/training/groundtruth/satImage_092_315.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "# initial data augmentation - rotate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import interpolation\n",
    "import skimage.io as io\n",
    "\n",
    "for i in range(1, 101):\n",
    "    for angle in [45, 90, 135, 180, 225, 270, 315]:\n",
    "        im = plt.imread(os.path.join(train_path, 'images', 'satImage_%.3d.png'%i))\n",
    "        im_r = interpolation.rotate(im, angle, order=1, reshape=False, mode='reflect')\n",
    "        io.imsave(os.path.join(train_path, 'images', 'satImage_%.3d_%.3d.png'%(i, angle)), im_r)\n",
    "\n",
    "        ma = plt.imread(os.path.join(train_path, 'groundtruth', 'satImage_%.3d.png'%i))\n",
    "        ma_r = interpolation.rotate(ma, angle, order=1, reshape=False, mode='reflect')\n",
    "        io.imsave(os.path.join(train_path, 'groundtruth', 'satImage_%.3d_%.3d.png'%(i, angle)), ma_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Metric / Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oA3rwAgMr_Nj"
   },
   "outputs": [],
   "source": [
    "# credits: https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DslNaQxLuHzK"
   },
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1606.04797.pdf\n",
    "# https://arxiv.org/pdf/1707.03237.pdf\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"Dice loss.\"\"\"\n",
    "    smooth = 1\n",
    "    y_pred_clip = K.clip(y_pred, 0, 1)\n",
    "    intersection = K.sum(y_true * y_pred_clip)\n",
    "    coefficient = (2. * intersection + smooth) / (K.sum(y_pred_clip) + K.sum(y_true) + smooth)\n",
    "    loss = 1. - coefficient\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U57_hYj3k1qp"
   },
   "outputs": [],
   "source": [
    "# foreground_threshold = 0.25\n",
    "\n",
    "# def patch_to_label(patch):\n",
    "#     df = np.mean(patch)\n",
    "#     if df > foreground_threshold:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "      \n",
    "# def get_label(y, patch_size=16):\n",
    "#     label = []\n",
    "#     y_array = K.eval(y[:,:,:,0])\n",
    "#     for im in y_array:\n",
    "#       for j in range(0, im.shape[1], patch_size):\n",
    "#         for i in range(0, im.shape[0], patch_size):\n",
    "#             patch = im[i:i + patch_size, j:j + patch_size]\n",
    "#             label.append(patch_to_label(patch))\n",
    "#     return np.array(label)\n",
    "  \n",
    "# def patch_f1(y_true, y_pred):\n",
    "#     true_label = get_label(y_true)\n",
    "#     pred_label = get_label(y_pred)\n",
    "#     return f1(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykKFQvakr_Np"
   },
   "outputs": [],
   "source": [
    "# # credits: https://www.kaggle.com/guglielmocamporese/macro-f1-score-keras\n",
    "\n",
    "# def f1(y_true, y_pred):\n",
    "#     #y_pred = K.round(y_pred)\n",
    "#     #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "#     return K.mean(f1)\n",
    "  \n",
    "# def f1_loss(y_true, y_pred):\n",
    "    \n",
    "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "#     f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "#     return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kz1V64Vojp1X"
   },
   "outputs": [],
   "source": [
    "# def adjustImage(img, mask):\n",
    "#     img = img/255\n",
    "#     mask = mask/255\n",
    "#     mask[mask > 0.5] = 1\n",
    "#     mask[mask <= 0.5] = 0\n",
    "#     return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gYQxiZ6heOr"
   },
   "outputs": [],
   "source": [
    "def preprocess_mask(mask):\n",
    "    mask = mask/255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return mask\n",
    "  \n",
    "def preprocess_img(img):\n",
    "    return img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGSyAjtzr_N3"
   },
   "outputs": [],
   "source": [
    "def trainvalGenerator(batch_size, train_path, image_folder, mask_folder,\n",
    "                      aug_dict, train_dir = None, val_dir = None,\n",
    "                      target_size = (400,400), seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    image_dict = aug_dict.copy()\n",
    "    image_dict[\"preprocessing_function\"] = preprocess_img\n",
    "    image_datagen = ImageDataGenerator(**image_dict)\n",
    "    \n",
    "    mask_dict = aug_dict.copy()\n",
    "    mask_dict[\"preprocessing_function\"] = preprocess_mask\n",
    "    mask_datagen = ImageDataGenerator(**mask_dict)\n",
    "    \n",
    "    # Train\n",
    "    image_generator_train = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = train_dir,\n",
    "        save_prefix  = \"image\",\n",
    "        seed = seed,\n",
    "        subset = \"training\")\n",
    "    \n",
    "    mask_generator_train = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"grayscale\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = train_dir,\n",
    "        save_prefix  = \"mask\",\n",
    "        seed = seed,\n",
    "        subset = \"training\")\n",
    "    \n",
    "    # Validation\n",
    "    image_generator_val = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = val_dir,\n",
    "        save_prefix  = \"image\",\n",
    "        seed = seed,\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    mask_generator_val = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"grayscale\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = val_dir,\n",
    "        save_prefix  = \"mask\",\n",
    "        seed = seed,\n",
    "        subset = \"validation\")\n",
    "    \n",
    "    return zip(image_generator_train, mask_generator_train), zip(image_generator_val, mask_generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWFE4TUsr_N7"
   },
   "outputs": [],
   "source": [
    "# argument for data augmentation\n",
    "data_gen_args = dict(rotation_range=45,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect',\n",
    "                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi8lvAUky7Gd"
   },
   "outputs": [],
   "source": [
    "!rm -rf train_image\n",
    "!rm -rf val_image\n",
    "!mkdir train_image\n",
    "!mkdir val_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "_Pr23xxNr_N_",
    "outputId": "ecbcf380-49d1-4f65-e37f-84da1722df70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 1 classes.\n",
      "Found 640 images belonging to 1 classes.\n",
      "Found 160 images belonging to 1 classes.\n",
      "Found 160 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen, valGen = trainvalGenerator(batch_size=2, \n",
    "                                     train_path=train_path, \n",
    "                                     image_folder='images', mask_folder='groundtruth',\n",
    "                                     aug_dict=data_gen_args, \n",
    "                                     train_dir = \"train_image\", # Set it to None if you don't want to save\n",
    "                                     val_dir = \"val_image\", # Set it to None if you don't want to save\n",
    "                                     target_size = (400, 400), seed = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7Gu5oZgCgie"
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filter, kernel_size=3, batchnorm=True, activation='relu'):\n",
    "    # first layer\n",
    "    x = Conv2D(n_filter, kernel_size=kernel_size, kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    # second layer\n",
    "    x = Conv2D(n_filter, kernel_size=kernel_size, kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yp2xDTpr_Nv"
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,\n",
    "         input_size = (None,None,3),\n",
    "         n_filter=16,\n",
    "         activation='relu',\n",
    "         dropout=True, dropout_rate=0.5,\n",
    "         batchnorm=True,\n",
    "         loss=binary_crossentropy\n",
    "        ):\n",
    "  \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = conv2d_block(inputs, n_filter, kernel_size=3, batchnorm=batchnorm, activation=activation)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = conv2d_block(pool1, n_filter*2, kernel_size=3, batchnorm=batchnorm, activation=activation)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = conv2d_block(pool2, n_filter*4, kernel_size=3, batchnorm=batchnorm, activation=activation)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = conv2d_block(pool3, n_filter*8, kernel_size=3, batchnorm=batchnorm, activation=activation)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = conv2d_block(pool4, n_filter*16, kernel_size=3, batchnorm=batchnorm, activation=activation)\n",
    "\n",
    "#     up6 = UpSampling2D(size = (2, 2))(conv5)\n",
    "#     up6 = conv2d_block(up6, n_filter*8, kernel_size=2, batchnorm=False, activation=activation)\n",
    "    up6 = Conv2DTranspose(n_filter*8, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(conv5)\n",
    "    \n",
    "    merge6 = concatenate([conv4, up6], axis = 3)\n",
    "    merge6 = Dropout(dropout_rate)(merge6) if dropout else merge6\n",
    "    \n",
    "    conv6 = conv2d_block(merge6, n_filter*8, kernel_size=3, batchnorm=False, activation=activation)\n",
    "    \n",
    "#     up7 = UpSampling2D(size = (2, 2))(conv6)\n",
    "#     up7 = conv2d_block(up7, n_filter*4, kernel_size=2, batchnorm=False, activation=activation)\n",
    "    up7 = Conv2DTranspose(n_filter*4, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(conv6)\n",
    "    \n",
    "    merge7 = concatenate([conv3, up7], axis = 3)\n",
    "    merge7 = Dropout(dropout_rate)(merge7) if dropout else merge7\n",
    "    \n",
    "    conv7 = conv2d_block(merge7, n_filter*4, kernel_size=3, batchnorm=False, activation=activation)\n",
    "    \n",
    "#     up8 = UpSampling2D(size = (2, 2))(conv7)\n",
    "#     up8 = conv2d_block(up8, n_filter*2, kernel_size=2, batchnorm=False, activation=activation)\n",
    "    up8 = Conv2DTranspose(n_filter*2, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(conv7)\n",
    "    \n",
    "    merge8 = concatenate([conv2, up8], axis = 3)\n",
    "    merge8 = Dropout(dropout_rate)(merge8) if dropout else merge8\n",
    "    \n",
    "    conv8 = conv2d_block(merge8, n_filter*2, kernel_size=3, batchnorm=False, activation=activation)\n",
    "    \n",
    "#     up9 = UpSampling2D(size = (2, 2))(conv8)\n",
    "#     up9 = conv2d_block(up9, n_filter, kernel_size=2, batchnorm=False, activation=activation)\n",
    "    up9 = Conv2DTranspose(n_filter, kernel_size=2, strides=2, kernel_initializer=\"he_normal\", padding='same')(conv8)\n",
    "    \n",
    "    merge9 = concatenate([conv1, up9], axis = 3)\n",
    "    merge9 = Dropout(dropout_rate)(merge9) if dropout else merge9\n",
    "    \n",
    "    conv9 = conv2d_block(merge9, n_filter, kernel_size=3, batchnorm=False, activation=activation)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr=1e-4), loss = loss, metrics = [f1, 'accuracy'])\n",
    "    \n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(filepath=pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use different model parameters to have different results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2487
    },
    "colab_type": "code",
    "id": "knx3uNw6r_OB",
    "outputId": "ae3a6b94-0f52-4759-ab54-81eaa9a5e2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 3 896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 3 128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 3 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 3 9248        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 3 128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 3 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, None, None, 3 0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 6 18496       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 6 36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 6 256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 6 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, None, None, 6 0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 1 512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, None, None, 1 0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 2 295168      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 2 1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 2 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 2 590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, None, None, 2 0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 5 1180160     max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 5 2359808     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 5 2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 5 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, None, None, 2 524544      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, None, None, 5 0           activation_44[0][0]              \n",
      "                                                                 conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, None, 5 0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 2 1179904     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 2 0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 2 590080      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 2 0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, None, None, 1 131200      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, None, 2 0           activation_42[0][0]              \n",
      "                                                                 conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, None, 2 0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 295040      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, None, None, 6 32832       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, None, None, 1 0           activation_40[0][0]              \n",
      "                                                                 conv2d_transpose_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, None, 1 0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 6 73792       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 6 0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 6 36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 6 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, None, None, 3 8224        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, None, None, 6 0           activation_38[0][0]              \n",
      "                                                                 conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, None, 6 0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 3 18464       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 3 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 3 9248        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 3 0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 33          activation_54[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,768,033\n",
      "Trainable params: 7,764,065\n",
      "Non-trainable params: 3,968\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet(\n",
    "             n_filter=32, # 16, 64, etc.\n",
    "             activation='elu', # or relu, etc.\n",
    "             batchnorm=True,\n",
    "             dropout=True,\n",
    "             dropout_rate=0.1, \n",
    "             loss=binary_crossentropy # dice_loss\n",
    "            )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ReAr6s7r_OG"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     ModelCheckpoint('weights_no_val.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "#     EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "#     ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_lr=1e-5),\n",
    "    ModelCheckpoint('weights_32_0.1_elu.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    TensorBoard(log_dir='tensorboard/', write_graph=True, write_images=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "pokgC4X9r_OX",
    "outputId": "9cdd9c55-4766-4f89-8c76-f41e08fffd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Fitting model...\n",
      "******************************\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 911s 455ms/step - loss: 0.2828 - f1: 0.7173 - acc: 0.8523 - val_loss: 0.1862 - val_f1: 0.8139 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18617, saving model to weights_32_0.1_elu_dice.h5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 923s 462ms/step - loss: 0.1887 - f1: 0.8114 - acc: 0.9138 - val_loss: 0.1651 - val_f1: 0.8349 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18617 to 0.16509, saving model to weights_32_0.1_elu_dice.h5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 927s 464ms/step - loss: 0.1678 - f1: 0.8323 - acc: 0.9240 - val_loss: 0.1634 - val_f1: 0.8367 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16509 to 0.16336, saving model to weights_32_0.1_elu_dice.h5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 903s 452ms/step - loss: 0.1525 - f1: 0.8475 - acc: 0.9309 - val_loss: 0.1618 - val_f1: 0.8382 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16336 to 0.16179, saving model to weights_32_0.1_elu_dice.h5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 849s 425ms/step - loss: 0.1441 - f1: 0.8559 - acc: 0.9342 - val_loss: 0.1541 - val_f1: 0.8460 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16179 to 0.15406, saving model to weights_32_0.1_elu_dice.h5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 844s 422ms/step - loss: 0.1332 - f1: 0.8668 - acc: 0.9393 - val_loss: 0.1633 - val_f1: 0.8368 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15406\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 842s 421ms/step - loss: 0.1269 - f1: 0.8731 - acc: 0.9419 - val_loss: 0.1587 - val_f1: 0.8413 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.15406\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 835s 418ms/step - loss: 0.1245 - f1: 0.8755 - acc: 0.9432 - val_loss: 0.1565 - val_f1: 0.8435 - val_acc: 0.9353\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15406\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 829s 414ms/step - loss: 0.1183 - f1: 0.8817 - acc: 0.9461 - val_loss: 0.1548 - val_f1: 0.8452 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15406\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 837s 419ms/step - loss: 0.1158 - f1: 0.8842 - acc: 0.9469 - val_loss: 0.1564 - val_f1: 0.8436 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15406\n"
     ]
    }
   ],
   "source": [
    "print('*'*30)\n",
    "print('Fitting model...')\n",
    "print('*'*30)\n",
    "history = model.fit_generator(generator=trainGen, steps_per_epoch=2000,\n",
    "                              validation_data=valGen, validation_steps=500,\n",
    "                              epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PT7H62qNCvMZ"
   },
   "outputs": [],
   "source": [
    "# !cp weights_32_0.1_elu.h5 \"drive/My Drive\"\n",
    "# # !cp weights_32_drop_relu.h5 \"drive/My Drive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsGVNX1nr_Oa"
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "def testGenerator(test_path, num_image = 50):\n",
    "    for i in range(1,num_image+1):\n",
    "        img = io.imread(os.path.join(test_path, \"test_%d\"%i, \"test_%d.png\"%i))\n",
    "        img = img / 255\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noWhzXJ3r_Od"
   },
   "outputs": [],
   "source": [
    "testGene = testGenerator(test_path)\n",
    "# model_predict = unet(pretrained_weights = \"weights_no_val_32.h5\", input_size = (608,608,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9hZnm9T18vEM",
    "outputId": "047acd1c-96b9-441a-adea-31488359b911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 7s 132ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_generator(testGene, 50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EdSPM5qRr_Oj",
    "outputId": "aba9266f-0450-47e7-f60c-a49ecd6b3bd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "def saveResult(save_path, npyfile):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path, \"%d_predict.png\"%(i+1)), img)\n",
    "\n",
    "!rm -rf test\n",
    "!mkdir test        \n",
    "saveResult(\"test\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWlLqIgRr_Ol"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6u0lzjwr_On"
   },
   "outputs": [],
   "source": [
    "# rename submission file\n",
    "submission_filename = 'submission_32_0.1_elu.csv'\n",
    "image_filenames = []\n",
    "predict_path = 'test/'\n",
    "for i in range(1, 51):\n",
    "    image_filename = predict_path + '%d' % i + '_predict.png'\n",
    "#     print(image_filename)\n",
    "    image_filenames.append(image_filename)\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXd0XEiwTpJ9"
   },
   "outputs": [],
   "source": [
    "# !cp submission_32_0.1_elu_dice.csv \"drive/My Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6bqSWCCHcGm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
